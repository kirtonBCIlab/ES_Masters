{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Relative Power of EEG Bands\n",
    "\n",
    "## Goals:\n",
    "1. **Data Import**\n",
    "    - Import the preprocessed data from npz and json files\n",
    "\n",
    "2. **Feature Extraction**\n",
    "    - Calculate the Power Spectral Density (PSD) for each epoch.\n",
    "    - Average PSD values across all epochs \n",
    "    - Get AUC across freq values for each frequency band\n",
    "    - Normalize AUC PSD values by computing the z-score for each\n",
    "    \n",
    "3. **Data Formatting**\n",
    "    - Export the data as (1, 12, 6, 1, 16, 4)\n",
    "        - (n_file, n_stimuli, (max)n_epochs, comfort_score, n_channels, n_bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# Custom libraries\n",
    "from Functions import processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Epoched Data and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of files to import\n",
    "files = [  \n",
    "    \"sub-P007-Redo_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P008-Redo_ses-S001_task-T2_run-001_eeg\"   \n",
    "]\n",
    "\n",
    "# Get unique subject IDs\n",
    "subject_ids = [file.split('_')[0].split('sub-')[1] for file in files]\n",
    "\n",
    "#spilt out the -Redo part of the subject IDs\n",
    "subject_ids = [subj_id.split('-Redo')[0] for subj_id in subject_ids]\n",
    "\n",
    "# Preallocate variables to store EEG data, settings, and comfort data\n",
    "eeg_epochs = [None] * len(files)\n",
    "settings = [None] * len(files)\n",
    "comfort_data_dicts = [None] * len(files)\n",
    "\n",
    "# Import data for each file\n",
    "for f, file in enumerate(files):\n",
    "    # Import EEG data, since it is stored in a compressed numpy file (.npz)\n",
    "    loaded_data = np.load(f\"Data\\\\Pilot-Data\\\\ML\\\\{file}.npz\", allow_pickle=True)\n",
    "    # Access the data for each stimulus\n",
    "    eeg_epochs[f] = {stim_label: loaded_data[stim_label] for stim_label in loaded_data.files}\n",
    "    \n",
    "    # Import settings\n",
    "    with open(f\"Data\\\\Pilot-Data\\\\ML\\\\{file}.json\", \"r\") as file_object:\n",
    "        settings[f] = json.load(file_object)\n",
    "    \n",
    "    # Import comfort data\"\n",
    "    comfort_data = pd.read_csv(f\"Data\\\\Pilot-Data\\\\ML\\\\{subject_ids[f]}-All-Comfort.csv\") \n",
    "    grouped = comfort_data.groupby([\"Contrast\", \"Size\"])\n",
    "    \n",
    "    # Create a dictionary for this subject: keys like \"ContrastXSizeY\" map to lists of comfort values\n",
    "    stim_comfort_dict = {}\n",
    "    for (contrast, size), group in grouped:\n",
    "        key = f\"Contrast{contrast}Size{size}\"\n",
    "        values = group[\"Comfort_Score\"].tolist()\n",
    "        stim_comfort_dict[key] = values\n",
    "        \n",
    "    # Save the per-subject comfort dictionary for later processing\n",
    "    comfort_data_dicts[f] = stim_comfort_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute PSD for each \"On\" Epoch\n",
    "\n",
    "- Calculate AUC for every channel for 4 freq bands\n",
    "    - Do not include the SSVEP stim freqs/harmonics in the frequency bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: (2, 12, 6, 16, 4)\n"
     ]
    }
   ],
   "source": [
    "# PSD settings\n",
    "window_size = 10  # For 10 second epochs: 10 = 0.1 Hz resolution, 5 = 0.2 Hz resolution, 2 = 0.5 Hz resolution\n",
    "\n",
    "# Preallocate variables\n",
    "eeg_f = [None] * len(files)\n",
    "eeg_pxx = [None] * len(files)  \n",
    "\n",
    "# Compute PSD for each file\n",
    "for f in range(len(files)):\n",
    "    eeg_f[f] = {}\n",
    "    eeg_pxx[f] = {}\n",
    "\n",
    "    for stim_label, epochs in eeg_epochs[f].items():  \n",
    "        eeg_f[f][stim_label] = []\n",
    "        eeg_pxx[f][stim_label] = []\n",
    "\n",
    "        for epoch in epochs:  \n",
    "            f_values, pxx_values = signal.welch(\n",
    "                x=epoch,  \n",
    "                fs=settings[f][\"eeg_srate\"],\n",
    "                nperseg=window_size * settings[f][\"eeg_srate\"],\n",
    "                noverlap=(window_size * settings[f][\"eeg_srate\"]) * 0.5,  \n",
    "            )\n",
    "            eeg_f[f][stim_label].append(f_values)\n",
    "            eeg_pxx[f][stim_label].append(pxx_values)\n",
    "\n",
    "        eeg_f[f][stim_label] = np.array(eeg_f[f][stim_label]) \n",
    "        eeg_pxx[f][stim_label] = np.array(eeg_pxx[f][stim_label]) \n",
    "\n",
    "# Define Frequency Bands\n",
    "eeg_bands = {\"delta\": [1, 4], \"theta\": [4, 8], \"alpha1\": [8, 9], \"alpha2\": [11, 13], \"beta1\": [13, 19], \"beta2\": [21, 30]}\n",
    "\n",
    "# Preallocate AUC array: (num_files, num_stimuli, max num_epochs, num_channels, num_bands)\n",
    "auc = np.zeros((len(files), len(eeg_pxx[0]), 6, len(settings[f]['ch_names']), 4))\n",
    "\n",
    "# Create a channel map to map new channel names to their indices in the full 16-channel layout and save for each file\n",
    "chan_map = {}\n",
    "\n",
    "for f in range(len(files)):\n",
    "    new_ch_names = settings[f]['new_ch_names']\n",
    "\n",
    "    # Create a mapping from new channel names to their indices in the full channel names, as a dict with channel names as keys\n",
    "    full_ch_names = settings[f]['ch_names']\n",
    "    chan_map[f] = {new_ch: full_ch_names.index(new_ch) for new_ch in new_ch_names if new_ch in full_ch_names}\n",
    "\n",
    "    for stim_idx, stim_label in enumerate(eeg_pxx[f]):\n",
    "        for epoch_idx in range(len(eeg_pxx[f][stim_label])):\n",
    "            for band_idx, (band_name, band_range) in enumerate(eeg_bands.items()):\n",
    "                fmask = (eeg_f[f][stim_label][0, :] >= band_range[0]) & (eeg_f[f][stim_label][0, :] <= band_range[1])\n",
    "                \n",
    "                # Integrate the PSD across the frequency range for each band\n",
    "                if band_name == 'delta':\n",
    "                    delta = np.trapezoid(eeg_pxx[f][stim_label][epoch_idx][:, fmask], x=eeg_f[f][stim_label][0, fmask], axis=1)\n",
    "                    for i, ch_idx in enumerate(chan_map[f].values()):\n",
    "                        auc[f, stim_idx, epoch_idx, ch_idx, 0] = delta[i]\n",
    "                elif band_name == 'theta':\n",
    "                    theta = np.trapezoid(eeg_pxx[f][stim_label][epoch_idx][:, fmask], x=eeg_f[f][stim_label][0, fmask], axis=1)\n",
    "                    for i, ch_idx in enumerate(chan_map[f].values()):\n",
    "                        auc[f, stim_idx, epoch_idx, ch_idx, 1] = theta[i]\n",
    "                elif band_name == 'alpha1':\n",
    "                    alpha1 = np.trapezoid(eeg_pxx[f][stim_label][epoch_idx][:, fmask], x=eeg_f[f][stim_label][0, fmask], axis=1)\n",
    "                elif band_name == 'alpha2':\n",
    "                    alpha2 = np.trapezoid(eeg_pxx[f][stim_label][epoch_idx][:, fmask], x=eeg_f[f][stim_label][0, fmask], axis=1)\n",
    "                    full_alpha = alpha1 + alpha2\n",
    "                    for i, ch_idx in enumerate(chan_map[f].values()):\n",
    "                        auc[f, stim_idx, epoch_idx, ch_idx, 2] = full_alpha[i]\n",
    "                elif band_name == 'beta1':\n",
    "                    beta1 = np.trapezoid(eeg_pxx[f][stim_label][epoch_idx][:, fmask], x=eeg_f[f][stim_label][0, fmask], axis=1)\n",
    "                elif band_name == 'beta2':\n",
    "                    beta2 = np.trapezoid(eeg_pxx[f][stim_label][epoch_idx][:, fmask], x=eeg_f[f][stim_label][0, fmask], axis=1)\n",
    "                    full_beta = beta1 + beta2\n",
    "                    for i, ch_idx in enumerate(chan_map[f].values()):\n",
    "                        auc[f, stim_idx, epoch_idx, ch_idx, 3] = full_beta[i]\n",
    "\n",
    "# Print shape of the final AUC array\n",
    "print(f\"AUC: {auc.shape}\") # (num_files, num_stimuli, max(num_epochs), num_channels, num_bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the AUC values\n",
    "- Z-score\n",
    "    * First reshape so all values are one long list for each participant \n",
    "        - $(1,\\ 12 \\times 6 \\times 16 \\times 4)$ for 1 file, 12 stimuli, 6 epochs, 16 channels, 4 frequency bands\n",
    "    * Compute the mean and std for all AUC PSD values, excluding the zero values (from bad channels)\n",
    "        - mean/std of 4,608 values (minus bads) for above example\n",
    "    * Reshape the mean/std arrays so they can be combined with the original auc array\n",
    "    * Calculate the z-score for each AUC PSD value\n",
    "        * **Formula**:  $\n",
    "\\text{PSD Z-score} = \\frac{\\text{AUC PSD}_{\\text{single channel/band}} - \\mu_{\\text{baseline}}}{\\sigma_{\\text{baseline}}}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized AUC: (2, 12, 6, 16, 4)\n"
     ]
    }
   ],
   "source": [
    "# Flatten each file's data: (num_files, -1)\n",
    "auc_reshaped = auc.reshape(auc.shape[0], -1)\n",
    "\n",
    "# Create a mask for non-zero values\n",
    "nonzero_mask = auc_reshaped != 0\n",
    "\n",
    "# Compute mean/std excluding zeros\n",
    "means = np.sum(auc_reshaped * nonzero_mask, axis=1, keepdims=True) / np.sum(nonzero_mask, axis=1, keepdims=True)\n",
    "stds = np.sqrt(np.sum(((auc_reshaped - means)**2) * nonzero_mask, axis=1, keepdims=True) / np.sum(nonzero_mask, axis=1, keepdims=True))\n",
    "\n",
    "# Avoid divide-by-zero\n",
    "stds[stds == 0] = 1\n",
    "\n",
    "# Compute z-scores and add 0 values back in\n",
    "auc_normalized_flat = (auc_reshaped - means) / stds\n",
    "auc_normalized_flat[~nonzero_mask] = 0\n",
    "\n",
    "# Reshape back to original\n",
    "auc_normalized = auc_normalized_flat.reshape(*auc.shape)\n",
    "\n",
    "# Print shape of the normalized AUC array\n",
    "print(f\"Normalized AUC: {auc_normalized.shape}\")  # (num_files, num_stimuli, max(num_epochs), num_channels, num_bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine stimuli, comfort scores, and PSD (per freq band)\n",
    "\n",
    "Shape will be (n_file, n_stimuli, (max)n_epochs, comfort_score, n_channels, n_bands)\n",
    "- for each stim it will be arr[f , stim] = (6, 1, 16, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml_input: (2, 12, 6, 1, 16, 4)\n",
      "[[ 5.06315393e-01 -2.73564294e-02 -3.57533751e-01 -2.34704789e-01]\n",
      " [ 3.52252610e-01 -1.64908720e-01 -3.86831015e-01 -2.80802322e-01]\n",
      " [ 3.43553536e-01 -2.24726961e-01 -4.22904281e-01 -2.83960376e-01]\n",
      " [ 1.16471595e-01 -1.87766282e-02 -2.86529120e-01 -1.78185576e-01]\n",
      " [ 1.00915487e-01 -1.31869841e-02 -2.99970139e-01 -1.56245134e-01]\n",
      " [-2.08667246e-04 -1.27747774e-01 -2.54685048e-01 -1.32058890e-01]\n",
      " [-1.68389463e-01 -3.63241657e-01 -3.96035498e-01 -3.05356775e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.53344376e-01 -2.94517720e-02 -1.78562305e-01  3.37839233e-01]\n",
      " [-8.59818043e-02 -1.36806745e-01 -2.85143879e-01  3.90232558e-01]\n",
      " [-2.14836118e-01 -1.55198911e-01 -3.41571896e-01 -1.94187758e-02]\n",
      " [-2.22892741e-01 -2.54795175e-01 -3.46612943e-01  1.27761900e-01]\n",
      " [-2.42065996e-01 -2.58898816e-01 -3.79369680e-01 -1.47568508e-01]\n",
      " [-2.42073210e-01 -3.08953283e-01 -4.00073904e-01 -2.29893577e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Preallocate array with the given shape\n",
    "ml_input = np.zeros((\n",
    "    len(files),                        # Number of files\n",
    "    len(eeg_pxx[0]),                   # Number of stimuli\n",
    "    6,                                 # Max Number of Epochs\n",
    "    1,                                 # Number of comfort scores per stimulus\n",
    "    len(settings[f]['ch_names']),  # Number of channels\n",
    "    4                                  # Number of bands\n",
    "))  \n",
    "\n",
    "eeg_bands = {\"delta\": [1, 4], \"theta\": [4, 8], \"alpha\": [8, 9], \"beta\": [13, 19]}\n",
    "\n",
    "for f in range(len(files)):\n",
    "    for stim_idx, stim_label in enumerate(eeg_pxx[f]):\n",
    "        for epoch_idx in range(len(eeg_pxx[f][stim_label])):\n",
    "            for comfort_idx, (c_stim_label, comfort_score) in enumerate(comfort_data_dicts[f].items()):\n",
    "                if stim_label == c_stim_label:\n",
    "                    # Get the specific comfort score for this epoch\n",
    "                    comfort_value = comfort_score[epoch_idx]\n",
    "\n",
    "                    for band_idx, (band_name, band_range) in enumerate(eeg_bands.items()):\n",
    "                            # Assign the AUC value to the ml_input array\n",
    "                            if band_name == 'delta':\n",
    "                                ml_input[f, stim_idx, epoch_idx, 0, :, 0] = auc_normalized[f, stim_idx, epoch_idx, :, 0]\n",
    "                            elif band_name == 'theta':\n",
    "                                ml_input[f, stim_idx, epoch_idx, 0, :, 1] = auc_normalized[f, stim_idx, epoch_idx, :, 1]\n",
    "                            elif band_name == 'alpha':\n",
    "                                ml_input[f, stim_idx, epoch_idx, 0, :, 2] = auc_normalized[f, stim_idx, epoch_idx, :, 2]\n",
    "                            elif band_name == 'beta':\n",
    "                                ml_input[f, stim_idx, epoch_idx, 0, :, 3] = auc_normalized[f, stim_idx, epoch_idx, :, 3]\n",
    "\n",
    "# Print shape of the ml_input array\n",
    "print(f\"ml_input: {ml_input.shape}\")    # (num_files, num_stimuli, max(num_epochs), comfort_score(n = 1), num_channels, num_bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save ML Input to CSV (individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to ml_input_output.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the EEG bands and channel names\n",
    "eeg_bands = {\"delta\": [1, 4], \"theta\": [4, 8], \"alpha\": [8, 9], \"beta\": [13, 19]}\n",
    "ch_names = [\"Fz\", \"F4\", \"F8\", \"C3\", \"Cz\", \"C4\", \"T8\", \"P7\", \"P3\", \"P4\", \"P8\", \"PO7\", \"PO8\", \"O1\", \"Oz\", \"O2\"]\n",
    "chan_map_full = {ch: idx for idx, ch in enumerate(ch_names)}\n",
    "\n",
    "# Define the structure for the CSV header\n",
    "eeg_band_columns = [\n",
    "    f\"{ch}_{band}\" for ch in settings[f]['ch_names'] for band in eeg_bands.keys()\n",
    "]\n",
    "header = ['Participant', 'Stimulus', 'Epoch', 'Comfort Score'] + eeg_band_columns\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open('Data\\\\Pilot-Data\\\\ML\\\\combined_ml_input.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    # Iterate through the ml_input data\n",
    "    for f in range(len(files)):\n",
    "        # Extract participant ID from filename\n",
    "        participant_id = subject_ids[f]\n",
    "\n",
    "        for stim_idx, stim_label in enumerate(eeg_pxx[f]):\n",
    "            for epoch_idx in range(len(eeg_pxx[f][stim_label])):\n",
    "                for comfort_idx, (c_stim_label, comfort_score) in enumerate(comfort_data_dicts[f].items()):\n",
    "                    if stim_label == c_stim_label:\n",
    "                        comfort_value = comfort_score[epoch_idx]\n",
    "                        \n",
    "                        row = [participant_id, stim_label, epoch_idx, comfort_value]\n",
    "                        \n",
    "                        channel_band_data = {f\"{ch}_{band}\": 0 for ch in ch_names for band in eeg_bands.keys()}\n",
    "                        \n",
    "                        for ch_idx, ch_name in enumerate(chan_map_full.items()):\n",
    "                            for band_idx, (band_name, band_range) in enumerate(eeg_bands.items()):\n",
    "                                if ch_name[0] in ch_names:\n",
    "                                    band_value = ml_input[f, stim_idx, epoch_idx, 0, ch_idx, band_idx]\n",
    "                                    channel_band_data[f\"{ch_name[0]}_{band_name}\"] = band_value\n",
    "                                            \n",
    "                        for ch_band in eeg_band_columns:\n",
    "                            row.append(channel_band_data[ch_band])\n",
    "                                \n",
    "                        writer.writerow(row)\n",
    "\n",
    "print(\"Data successfully written to ml_input_output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bessy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
