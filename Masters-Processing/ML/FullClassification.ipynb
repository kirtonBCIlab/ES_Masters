{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9769dbbf",
   "metadata": {},
   "source": [
    "# EEG Comfort Score Prediction\n",
    " \n",
    "# This notebook implements an improved approach to predicting comfort scores from EEG features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd345ce",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10039bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, f_classif, mutual_info_classif, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                            f1_score, roc_auc_score, confusion_matrix, \n",
    "                            roc_curve, precision_recall_curve, \n",
    "                            average_precision_score)\n",
    "\n",
    "\n",
    "import mrmr\n",
    "from mrmr import mrmr_classif, mrmr_regression\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f6a4c0",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84b53fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Comfort Score == 3: 100\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = \"features-Master.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Shuffle the data\n",
    "shuffled = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "data_shuffled = shuffled.iloc[:, 4:]\n",
    "labels_shuffled = shuffled[\"Comfort Score\"]\n",
    "\n",
    "print(\"Number of Comfort Score == 3:\", (labels_shuffled == 3).sum())\n",
    "\n",
    "# Create binary labels (1,2 = 0; 4,5 = 1; exclude 3 for clearer separation)\n",
    "binary_labels = labels_shuffled.apply(lambda x: 0 if x <= 2 else (1 if x >=4 else np.nan))\n",
    "binary_data = data_shuffled[~binary_labels.isna()]\n",
    "binary_labels = binary_labels[~binary_labels.isna()] ###############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb34641",
   "metadata": {},
   "source": [
    "## 3. Data Splitting and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be7ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For binary classification\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(\n",
    "    binary_data,\n",
    "    binary_labels,\n",
    "    test_size=0.2,\n",
    "    stratify=binary_labels,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430fd28d",
   "metadata": {},
   "source": [
    "## 4. Scale features\n",
    "- Make sure these are used consistently in all future code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4920cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_bin_scaled = pd.DataFrame(scaler.fit_transform(X_train_bin))\n",
    "X_test_bin_scaled = pd.DataFrame(scaler.transform(X_test_bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae2d8b2",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5128fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate models\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name=\"\"):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # For regression\n",
    "    if isinstance(model, (RandomForestRegressor, GradientBoostingRegressor, \n",
    "                         SVR, XGBRegressor, CatBoostRegressor)):\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"{model_name} - RMSE: {rmse:.4f}, RÂ²: {r2:.4f}\")\n",
    "        return r2\n",
    "    \n",
    "    # For classification\n",
    "    else:\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"{model_name} - Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {model_name}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.show()\n",
    "        \n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc995d8",
   "metadata": {},
   "source": [
    "### 5.1 Binary Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1b072fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classification Performance:\n"
     ]
    }
   ],
   "source": [
    "# Initialize classification models\n",
    "class_models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42),\n",
    "    \"SVM\": SVC(random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "print(\"Binary Classification Performance:\")\n",
    "#for name, model in class_models.items():\n",
    "#    evaluate_model(model, X_train_bin_scaled, X_test_bin_scaled, \n",
    "#                  y_train_bin, y_test_bin, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b04668",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRMRTransformer:\n",
    "    def __init__(self, k_features):\n",
    "        self.k_features = k_features\n",
    "        self.selected_features = None\n",
    "        self.column_names = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Convert to DataFrame if not already\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        \n",
    "        # Reset indices to avoid alignment issues\n",
    "        X = X.reset_index(drop=True)\n",
    "        y = pd.Series(y).reset_index(drop=True)\n",
    "        \n",
    "        self.column_names = X.columns.tolist()\n",
    "        try:\n",
    "            self.selected_features = mrmr_regression(X, y, K=self.k_features)\n",
    "        except:\n",
    "            # Fallback to random features if MRMR fails\n",
    "            self.selected_features = np.random.choice(X.columns, size=min(self.k_features, len(X.columns)), replace=False)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X, columns=self.column_names)\n",
    "        return X[self.selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea1aa6",
   "metadata": {},
   "source": [
    "# Binary Classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f3d87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 14:23:51,057] A new study created in memory with name: no-name-3a3bf92d-b383-4f82-8e68-619a65602a52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6577ba3b623648c8b029ee490d57d2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = X_train_bin_scaled.copy()\n",
    "y = y_train_bin.copy()\n",
    "\n",
    "def binary_classification_objective(trial):\n",
    "    # 1. Imputation\n",
    "    impute_method = trial.suggest_categorical('imputation', ['mean', 'median', 'knn', 'iterative'])\n",
    "    if impute_method == 'mean':\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "    elif impute_method == 'median':\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "    elif impute_method == 'knn':\n",
    "        imputer = KNNImputer(n_neighbors=trial.suggest_int('knn_neighbors', 3, 15))\n",
    "    else:\n",
    "        imputer = IterativeImputer(\n",
    "            max_iter=trial.suggest_int('iterative_max_iter', 10, 50),\n",
    "            random_state=42,\n",
    "            tol=0.01\n",
    "        )\n",
    "\n",
    "    # 2. Feature selection\n",
    "    fs_method = trial.suggest_categorical('feature_selection', ['ANOVA', 'MutualInfo', 'RFE', 'None'])\n",
    "    selector = 'passthrough'  # Default if no feature selection\n",
    "    \n",
    "    if fs_method != 'None':\n",
    "        k_features = trial.suggest_int('k_features', 10, min(50, X.shape[1]))\n",
    "        \n",
    "        if fs_method == 'ANOVA':\n",
    "            selector = SelectKBest(f_classif, k=k_features)\n",
    "        elif fs_method == 'MutualInfo':\n",
    "            selector = SelectKBest(mutual_info_classif, k=k_features)\n",
    "        elif fs_method == 'RFE':\n",
    "            rfe_step = trial.suggest_float('rfe_step', 0.1, 1.0)\n",
    "            estimator = RandomForestClassifier(\n",
    "                n_estimators=trial.suggest_int('rfe_n_estimators', 50, 200),\n",
    "                max_depth=trial.suggest_int('rfe_max_depth', 3, 10),\n",
    "                random_state=42\n",
    "            )\n",
    "            selector = RFE(estimator, n_features_to_select=k_features, step=rfe_step)\n",
    "    \n",
    "    # 3. Model selection and hyperparameters\n",
    "    model_name = trial.suggest_categorical('model', ['RandomForest', 'GradientBoosting', 'XGBoost', 'SVM', 'CatBoost'])\n",
    "    \n",
    "    if model_name == 'RandomForest':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "            'random_state': 42\n",
    "        }\n",
    "        model = RandomForestClassifier(**params)\n",
    "        \n",
    "    elif model_name == 'GradientBoosting':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'random_state': 42\n",
    "        }\n",
    "        model = GradientBoostingClassifier(**params)\n",
    "        \n",
    "    elif model_name == 'XGBoost':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "            'random_state': 42,\n",
    "            'eval_metric': 'logloss',\n",
    "            'use_label_encoder': False\n",
    "        }\n",
    "        model = XGBClassifier(**params)\n",
    "        \n",
    "    elif model_name == 'SVM':\n",
    "        kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly'])\n",
    "        params = {\n",
    "            'C': trial.suggest_float('C', 0.1, 100, log=True),\n",
    "            'kernel': kernel,\n",
    "            'gamma': trial.suggest_categorical('gamma', ['scale', 'auto']),\n",
    "            'degree': trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3,\n",
    "            'probability': True,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        model = SVC(**params)\n",
    "        \n",
    "    else:  # CatBoost\n",
    "        params = {\n",
    "            'iterations': trial.suggest_int('catboost_iterations', 100, 1000),\n",
    "            'depth': trial.suggest_int('catboost_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('catboost_learning_rate', 0.001, 0.3, log=True),\n",
    "            'l2_leaf_reg': trial.suggest_float('catboost_l2_leaf_reg', 1e-8, 10.0, log=True),\n",
    "            'border_count': trial.suggest_int('catboost_border_count', 32, 255),\n",
    "            'random_strength': trial.suggest_float('catboost_random_strength', 1e-9, 10, log=True),\n",
    "            'bagging_temperature': trial.suggest_float('catboost_bagging_temperature', 0.0, 1.0),\n",
    "            'random_state': 42,\n",
    "            'verbose': False\n",
    "        }\n",
    "        model = CatBoostClassifier(**params)\n",
    "\n",
    "    # 4. Pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', imputer),\n",
    "        ('feature_selection', selector),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # 5. Cross-validation with proper scoring for classification\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    try:\n",
    "        scores = cross_val_score(pipeline, X, y, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "        return np.mean(scores)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in trial: {e}\")\n",
    "        return -np.inf\n",
    "\n",
    "# Run binary classification study\n",
    "binary_study = optuna.create_study(direction='maximize')\n",
    "binary_study.optimize(binary_classification_objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nBinary Classification Optimization Results:\")\n",
    "print(f\"Best ROC AUC: {binary_study.best_value:.4f}\")\n",
    "print(\"Best Parameters:\")\n",
    "for key, value in binary_study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c369ab82",
   "metadata": {},
   "source": [
    "# Apply best imputation and feature selection to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6790bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best imputation method from study\n",
    "best_impute_method = binary_study.best_params.get('imputation', 'mean')\n",
    "\n",
    "# Apply the best imputation method\n",
    "if best_impute_method == 'mean':\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "elif best_impute_method == 'median':\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "elif best_impute_method == 'knn':\n",
    "    imputer = KNNImputer(n_neighbors=study.best_params.get('knn_neighbors', 5))\n",
    "elif best_impute_method == 'iterative':\n",
    "    imputer = IterativeImputer(\n",
    "        max_iter=study.best_params.get('iterative_max_iter', 50),\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "# Fit and transform the data\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Convert back to DataFrame (if needed)\n",
    "if isinstance(X, pd.DataFrame):\n",
    "    X_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# Now apply your feature selection code from before\n",
    "best_fs_method = study.best_params.get('feature_selection', 'None')\n",
    "\n",
    "if best_fs_method != 'None':\n",
    "    k_features = study.best_params['k_features']\n",
    "    \n",
    "    if best_fs_method == 'ANOVA':\n",
    "        selector = SelectKBest(f_regression, k=k_features)\n",
    "    elif best_fs_method == 'MutualInfo':\n",
    "        selector = SelectKBest(mutual_info_regression, k=k_features)\n",
    "    elif best_fs_method == 'RFE':\n",
    "        estimator = RandomForestRegressor(\n",
    "            n_estimators=study.best_params.get('rfe_n_estimators', 100),\n",
    "            max_depth=study.best_params.get('rfe_max_depth', 5),\n",
    "            random_state=42\n",
    "        )\n",
    "        selector = RFE(\n",
    "            estimator, \n",
    "            n_features_to_select=k_features,\n",
    "            step=study.best_params.get('rfe_step', 1)\n",
    "        )\n",
    "    elif best_fs_method == 'MRMR':\n",
    "        selector = MRMRTransformer(k_features=k_features)\n",
    "    \n",
    "    selector.fit(X_imputed, y)\n",
    "    if hasattr(selector, 'get_support'):  # For SelectKBest/RFE\n",
    "        selected_features = X.columns[selector.get_support()]\n",
    "    else:  # For MRMRTransformer\n",
    "        selected_features = selector.selected_features\n",
    "    X_best = X_imputed[selected_features]\n",
    "else:\n",
    "    X_best = X_imputed\n",
    "    selected_features = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1280fdd6",
   "metadata": {},
   "source": [
    "# Apply best model and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data with same transformations as training\n",
    "# 1. Apply the same imputation\n",
    "X_test_imputed = imputer.transform(X_test_bin_scaled)  # Use the already fitted imputer\n",
    "\n",
    "# Convert back to DataFrame if needed\n",
    "if isinstance(X_test_bin_scaled, pd.DataFrame):\n",
    "    X_test_imputed = pd.DataFrame(X_test_imputed, columns=X_test_bin_scaled.columns)\n",
    "\n",
    "# 2. Apply the same feature selection\n",
    "if best_fs_method != 'None':\n",
    "    if best_fs_method == 'MRMR':\n",
    "        X_test_final = X_test_imputed[selected_features]\n",
    "    else:\n",
    "        X_test_final = selector.transform(X_test_imputed)  # Use the already fitted selector\n",
    "        if isinstance(X_test_imputed, pd.DataFrame):\n",
    "            X_test_final = pd.DataFrame(X_test_final, columns=selected_features)\n",
    "else:\n",
    "    X_test_final = X_test_imputed\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test_final)\n",
    "y_pred_proba = best_model.predict_proba(X_test_final)[:, 1]  # Probabilities for class 1\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test_bin, y_pred)\n",
    "precision = precision_score(y_test_bin, y_pred)\n",
    "recall = recall_score(y_test_bin, y_pred)\n",
    "f1 = f1_score(y_test_bin, y_pred)\n",
    "roc_auc = roc_auc_score(y_test_bin, y_pred_proba)\n",
    "\n",
    "print(\"\\nFinal Model Evaluation on Test Set:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_bin, y_pred)\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.title('Confusion Matrix - Best Binary Model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test_bin, y_pred_proba)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test_bin, y_pred_proba)\n",
    "average_precision = average_precision_score(y_test_bin, y_pred_proba)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(recall_curve, precision_curve, label=f'Precision-Recall curve (AP = {average_precision:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638e9cd",
   "metadata": {},
   "source": [
    "# Evaluate with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data with same transformations as training\n",
    "# 1. Apply the same imputation\n",
    "X_test_imputed = imputer.transform(X_test_bin_scaled)  # Use the already fitted imputer\n",
    "\n",
    "# Convert back to DataFrame if needed\n",
    "if isinstance(X_test_bin_scaled, pd.DataFrame):\n",
    "    X_test_imputed = pd.DataFrame(X_test_imputed, columns=X_test_bin_scaled.columns)\n",
    "\n",
    "# 2. Apply the same feature selection\n",
    "if best_fs_method != 'None':\n",
    "    if best_fs_method == 'MRMR':\n",
    "        X_test_final = X_test_imputed[selected_features]\n",
    "    else:\n",
    "        X_test_final = selector.transform(X_test_imputed)  # Use the already fitted selector\n",
    "        if isinstance(X_test, pd.DataFrame):\n",
    "            X_test_final = pd.DataFrame(X_test_final, columns=selected_features)\n",
    "else:\n",
    "    X_test_final = X_test_imputed\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test_final)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test_bin, y_pred))\n",
    "r2 = r2_score(y_test_bin, y_pred)\n",
    "\n",
    "print(\"\\nFinal Model Evaluation on Test Set:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"RÂ²: {r2:.4f}\")\n",
    "\n",
    "# Calculate accuracy within Â±1 point\n",
    "correct = np.sum(np.abs(y_test_bin - y_pred) <= 1)\n",
    "accuracy = correct / len(y_test_bin)\n",
    "print(f\"Accuracy within Â±1 point: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_bin, y_pred_bin)\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Best Binary Model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bessy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
