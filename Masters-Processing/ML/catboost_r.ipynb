{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb0855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "from sklearn.pipeline import Pipeline\n",
    "import mrmr\n",
    "from mrmr import mrmr_regression\n",
    "import warnings\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd70c89",
   "metadata": {},
   "source": [
    "# Import and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca7485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = \"features-Master.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Shuffle the data\n",
    "shuffled = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "data_shuffled = shuffled.iloc[:, 4:]\n",
    "labels_shuffled = shuffled[\"Comfort Score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3af852",
   "metadata": {},
   "source": [
    "# Class to Accomodate MRMR Feature Selection Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6032c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRMRTransformer:\n",
    "    def __init__(self, k_features):\n",
    "        self.k_features = k_features\n",
    "        self.selected_features = None\n",
    "        self.column_names = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Convert to DataFrame if not already\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        \n",
    "        # Reset indices to avoid alignment issues\n",
    "        X = X.reset_index(drop=True)\n",
    "        y = pd.Series(y).reset_index(drop=True)\n",
    "        \n",
    "        self.column_names = X.columns.tolist()\n",
    "        try:\n",
    "            self.selected_features = mrmr_regression(X, y, K=self.k_features)\n",
    "            print(\"Got MRMR features\")\n",
    "        except:\n",
    "            # Fallback to random features if MRMR fails\n",
    "            self.selected_features = np.random.choice(X.columns, size=min(self.k_features, len(X.columns)), replace=False)\n",
    "            print(\"MRMR failed, selected random features instead.\")\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X, columns=self.column_names)\n",
    "        return X[self.selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5eacf1",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd4383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For regression (using stratified split based on binned target)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_shuffled, \n",
    "    labels_shuffled, \n",
    "    test_size=0.2, \n",
    "    stratify=labels_shuffled,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a999dce",
   "metadata": {},
   "source": [
    "# Optimize Feature Selection and Catboost Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.copy()\n",
    "y = y_train.copy().values\n",
    "\n",
    "def objective(trial):\n",
    "    # 1. Feature Selection\n",
    "    fs_method = trial.suggest_categorical('feature_selection', ['RFE', 'MRMR', 'None'])\n",
    "    if fs_method != 'None':\n",
    "        k_features = trial.suggest_int('k_features', 5, 105, step = 10) # Can edit step size and log bool (log is strange though)\n",
    "        if fs_method == 'RFE':\n",
    "            #rfe_step = trial.suggest_float('rfe_step', 0.1, 1.0, step=0.1) #### Can edit step size. This is the fraction of features to remove at each iteration of feature elimination https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\n",
    "            estimator = RandomForestRegressor()\n",
    "                #n_estimators=trial.suggest_int('rfe_n_estimators', 50, 200),\n",
    "                #max_depth=trial.suggest_int('rfe_max_depth', 3, 10),\n",
    "                #random_state=42\n",
    "            selector = RFE(estimator, n_features_to_select=k_features)\n",
    "        elif fs_method == 'MRMR':\n",
    "            selector = MRMRTransformer(k_features=k_features) #https://feature-engine.trainindata.com/en/1.8.x/api_doc/selection/MRMR.html#feature_engine.selection.MRMR\n",
    "    else:\n",
    "        selector = 'passthrough'\n",
    "\n",
    "    # 2. CatBoost Parameters\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000, step=25),\n",
    "        'depth': trial.suggest_int('depth', 6, 10), #https://catboost.ai/docs/en/concepts/parameter-tuning\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True), #https://forecastegy.com/posts/catboost-hyperparameter-tuning-guide-with-optuna/\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True), \n",
    "        'random_strength': trial.suggest_float('random_strength', 1e-9, 10, log=True),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'random_seed': 42,\n",
    "        'verbose': False,\n",
    "    }\n",
    "    model = CatBoostRegressor(**params)\n",
    "\n",
    "    # 3. Pipeline \n",
    "    pipeline = Pipeline([\n",
    "        ('feature_selection', selector),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    #4. Cross-validation\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    try:\n",
    "        scores = cross_val_score(pipeline, X, y, cv=cv, scoring='r2', n_jobs=1)\n",
    "        return np.mean(scores)\n",
    "    except Exception:\n",
    "        return -np.inf\n",
    "\n",
    "# Run Optuna Study\n",
    "study = optuna.create_study(direction='maximize') # sampler = optuna.samplers.QMCSampler()) https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.QMCSampler.html#optuna.samplers.QMCSampler\n",
    "study.optimize(objective, n_trials=5, show_progress_bar=True, n_jobs=6) \n",
    "\n",
    "# Best result\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"R²: {trial.value:.4f}\")\n",
    "print(\"Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6347008",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Parameter Importance Plot\n",
    "fig = vis.plot_param_importances(study, target_name=\"R² Score\")\n",
    "fig.show()\n",
    "\n",
    "# 2. Slice Plot (Best for seeing individual parameter effects)\n",
    "fig = vis.plot_slice(\n",
    "    study,\n",
    "    params=[\n",
    "        'iterations',\n",
    "        'feature_selection',\n",
    "        'depth',\n",
    "        'learning_rate',\n",
    "        'k_features'\n",
    "    ],\n",
    "    target_name=\"R² Score\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb4526",
   "metadata": {},
   "source": [
    "# Apply Feature Selection to Training & Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193973de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply your feature selection code from before\n",
    "best_fs_method = study.best_params.get('feature_selection', 'None')\n",
    "\n",
    "if best_fs_method != 'None':\n",
    "    k_features = study.best_params['k_features']\n",
    "    if best_fs_method == 'RFE':\n",
    "        estimator = RandomForestRegressor()\n",
    "            #n_estimators=study.best_params.get('rfe_n_estimators', 100),\n",
    "            #max_depth=study.best_params.get('rfe_max_depth', 5),\n",
    "            #random_state=42\n",
    "        selector = RFE(\n",
    "            estimator, \n",
    "            n_features_to_select=k_features,\n",
    "           # step=study.best_params.get('rfe_step', 1)\n",
    "        )\n",
    "    elif best_fs_method == 'MRMR':\n",
    "        selector = MRMRTransformer(k_features=k_features)\n",
    "    \n",
    "    selector.fit(X, y)\n",
    "    if hasattr(selector, 'get_support'):  # For SelectKBest/RFE\n",
    "        selected_features = X.columns[selector.get_support()]\n",
    "    else:  # For MRMRTransformer\n",
    "        selected_features = selector.selected_features\n",
    "    X_best = X[selected_features]\n",
    "else:\n",
    "    X_best = X\n",
    "    selected_features = X.columns\n",
    "\n",
    "# Apply the same feature selection to test data\n",
    "if best_fs_method != 'None':\n",
    "    if best_fs_method == 'MRMR':\n",
    "        X_test_final = X_test[selected_features]\n",
    "    else:\n",
    "        X_test_final = selector.transform(X_test)  # Use the already fitted selector\n",
    "        if isinstance(X_test, pd.DataFrame):\n",
    "            X_test_final = pd.DataFrame(X_test_final, columns=selected_features)\n",
    "else:\n",
    "    X_test_final = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e0cd50",
   "metadata": {},
   "source": [
    "# Create Catboost Model with Optimized Parameters and Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff4ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = CatBoostRegressor(\n",
    "    iterations=study.best_params['iterations'],\n",
    "    depth=study.best_params['depth'],\n",
    "    learning_rate=study.best_params['learning_rate'],\n",
    "    l2_leaf_reg= study.best_params['l2_leaf_reg'],\n",
    "    random_strength=study.best_params['random_strength'],\n",
    "    bagging_temperature=study.best_params['bagging_temperature'],\n",
    "    border_count=study.best_params['border_count'],\n",
    "    random_seed = 42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Train on full imputed data\n",
    "best_model.fit(X_best, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a891d95",
   "metadata": {},
   "source": [
    "# Run Model and Get Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test_final)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nFinal Model Evaluation on Test Set:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# Calculate accuracy within ±1 point\n",
    "correct = np.sum(np.abs(y_test - y_pred) <= 1)\n",
    "accuracy = correct / len(y_test)\n",
    "print(f\"Accuracy within ±1 point: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bessy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
