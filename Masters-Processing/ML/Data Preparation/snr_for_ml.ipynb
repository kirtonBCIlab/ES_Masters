{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7020bed1",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b5234f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../Functions\"))\n",
    "\n",
    "# Custom libraries\n",
    "import processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eef3a2d",
   "metadata": {},
   "source": [
    "# Import Epoched Data and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c4536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of files to import\n",
    "files = [  \n",
    "    \"sub-P001_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P002_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P003_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P004_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P005_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P006_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P007_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P008_ses-S001_task-T1_run-001_eeg\", \n",
    "    \"sub-P009_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P010_ses-S001_task-T1_run-001_eeg\",  \n",
    "]\n",
    "\n",
    "# Get unique subject IDs\n",
    "subject_ids = [file.split('_')[0] for file in files]\n",
    "unique_subject_ids = list(set(subject_ids))\n",
    "\n",
    "# Preallocate variables to store EEG data and settings\n",
    "loaded_data = [None] * len(files)\n",
    "eeg_epochs = [{} for _ in range(len(files))]\n",
    "settings = [None] * len(files)\n",
    "\n",
    "# Import data\n",
    "for f, file in enumerate(files):\n",
    "    for sub in subject_ids:\n",
    "        if sub == file.split('_')[0]:\n",
    "            # Import EEG data, since it is stored in a compressed numpy file (.npz) we need to use the np.load function \n",
    "            loaded_data[f]= np.load(f\"..\\\\Data\\\\Pilot2\\\\EEG\\\\{sub}\\\\ses-S001\\\\eeg\\\\{file}.npz\", allow_pickle=True)\n",
    "\n",
    "\n",
    "            # Access the data for each stimulus\n",
    "            eeg_epochs[f] = {stim_label: loaded_data[f][stim_label] for stim_label in loaded_data[f]}\n",
    "\n",
    "            # Import settings\n",
    "            with open(f\"..\\\\Data\\\\Pilot2\\\\EEG\\\\{sub}\\\\ses-S001\\\\eeg\\\\{file}.json\", \"r\") as file_object:\n",
    "                settings[f] = json.load(file_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab71e1c",
   "metadata": {},
   "source": [
    "# Calculate PSD of all Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49ca342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\miniconda3\\envs\\bessy\\Lib\\site-packages\\scipy\\signal\\_spectral_py.py:790: UserWarning: nperseg = 1280 is greater than input length  = 1279, using nperseg = 1279\n",
      "  freqs, _, Pxy = _spectral_helper(x, y, fs, window, nperseg, noverlap,\n"
     ]
    }
   ],
   "source": [
    "# PSD settings\n",
    "window_size = 5\n",
    "\n",
    "# Preallocate variables\n",
    "eeg_f = [None] * len(files)\n",
    "eeg_pxx = [None] * len(files)  # Preallocate to list in case not all files have the same number of channels\n",
    "\n",
    "# Compute PSD for each file\n",
    "for f, file in enumerate(files):\n",
    "    eeg_f[f] = {}\n",
    "    eeg_pxx[f] = {}\n",
    "\n",
    "    # Compute PSD for each stimulus\n",
    "    for stim_label, epochs in eeg_epochs[f].items():\n",
    "        eeg_f[f][stim_label] = []\n",
    "        eeg_pxx[f][stim_label] = []\n",
    "\n",
    "        # Compute PSD for each epoch\n",
    "        for epoch in epochs:\n",
    "            f_values, pxx_values = signal.welch(\n",
    "                x=epoch,\n",
    "                fs=settings[f][\"eeg_srate\"],\n",
    "                nfft=int(window_size * settings[f][\"eeg_srate\"]),\n",
    "                nperseg=window_size * settings[f][\"eeg_srate\"],\n",
    "                noverlap= (window_size * settings[f][\"eeg_srate\"]) * 0.5,  # 50% overlap between windows\n",
    "            )\n",
    "            eeg_f[f][stim_label].append(f_values)\n",
    "            eeg_pxx[f][stim_label].append(pxx_values)\n",
    "\n",
    "        # Convert lists to arrays for consistency\n",
    "        eeg_f[f][stim_label] = np.array(eeg_f[f][stim_label])\n",
    "        eeg_pxx[f][stim_label] = np.array(eeg_pxx[f][stim_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d8af3c",
   "metadata": {},
   "source": [
    "# Compute SNR for all Epochs\n",
    "- SNR is calculated for each epoch and is NOT averaged per stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee466b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "noise_band = 1    # Single-sided noise band [Hz]\n",
    "nharms = 2        # Number of harmonics used\n",
    "db_out = True     # Boolean to get output in dB\n",
    "stim_freq = 10.0  # Stimulus frequency [Hz]\n",
    "\n",
    "snr = [None] * len(files)\n",
    "\n",
    "for f in range(len(files)):\n",
    "    stim_labels = list(settings[f][\"stimuli\"].values())\n",
    "    file_channels = settings[f][\"new_ch_names\"]\n",
    "    ch_idx_map = {ch: i for i, ch in enumerate(file_channels)}\n",
    "\n",
    "    if snr[f] is None:\n",
    "        snr[f] = {}  # Init dict per file\n",
    "\n",
    "    for stim_idx, stim_label in settings[f][\"stimuli\"].items():\n",
    "        num_epochs = eeg_pxx[f][stim_label].shape[0]\n",
    "        channel_snr_list = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            snr_epoch = processing.ssvep_snr(\n",
    "                f=eeg_f[f][stim_label][epoch],  # shape: (n_freqs,)\n",
    "                pxx=eeg_pxx[f][stim_label][epoch, :, :],  # shape: (n_channels, n_freqs)\n",
    "                stim_freq=stim_freq,\n",
    "                noise_band=noise_band,\n",
    "                nharms=nharms,\n",
    "                db_out=db_out\n",
    "            )\n",
    "            channel_snr_list.append(snr_epoch)\n",
    "\n",
    "        # Create array: shape = (num_epochs, total_channels)\n",
    "        epoch_snr_stack = np.zeros((num_epochs, len(file_channels)))\n",
    "\n",
    "        for epoch_idx in range(num_epochs):\n",
    "            for i, ch_name in enumerate(file_channels):\n",
    "                if ch_name in ch_idx_map:\n",
    "                    epoch_snr_stack[epoch_idx, i] = channel_snr_list[epoch_idx][ch_idx_map[ch_name]]\n",
    "                else:\n",
    "                    epoch_snr_stack[epoch_idx, i] = 0  # Channel missing\n",
    "\n",
    "        # Store per stimulus\n",
    "        snr[f][stim_label] = epoch_snr_stack  # shape: (num_epochs, total_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8664fa1f",
   "metadata": {},
   "source": [
    "# Export SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f5af35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "export = True\n",
    "\n",
    "if export:\n",
    "    records = []\n",
    "\n",
    "    for f, file in enumerate(files):\n",
    "        participant_id = file.split('_')[0]\n",
    "\n",
    "        # Iterate over stimuli \n",
    "        for s, stimulus in settings[f][\"stimuli\"].items():\n",
    "            n_epochs = len(snr[f][stimulus])  # Safe number of available epochs\n",
    "       \n",
    "            for epoch_idx in range(n_epochs):\n",
    "                row = {\n",
    "                    'Participant': participant_id,\n",
    "                    'Stimulus': stimulus,\n",
    "                    'Epoch': epoch_idx,\n",
    "                }\n",
    "\n",
    "                temp_snr = snr[f][stimulus][epoch_idx]  # shape: (channels,)\n",
    "\n",
    "                for ch_idx, ch_name in enumerate(settings[f][\"new_ch_names\"]):\n",
    "                    col_name = f\"{ch_name}_SNR\"\n",
    "                    row[col_name] = temp_snr[ch_idx]\n",
    "\n",
    "                records.append(row)\n",
    "\n",
    "# Combine all into one DataFrame and save\n",
    "df_all = pd.DataFrame(records)\n",
    "df_all.to_csv(\"all_participants_SNR.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bessy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
