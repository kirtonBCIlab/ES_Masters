{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "- import pre-processedd data\n",
    "- import z scores\n",
    "- import comfort scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Simulate EEG data (replace with actual data loading)\n",
    "# Example: 1000 samples, each with 128 time steps, and 8 EEG channels\n",
    "eeg_data = np.random.rand(1000, 128, 8)  # Shape: (samples, time steps, features)\n",
    "stimulus_rankings = np.random.randint(1, 6, size=(1000,))  # Comfort rankings (1 to 5)\n",
    "\n",
    "# Normalize EEG data\n",
    "scaler = StandardScaler()\n",
    "eeg_data = eeg_data.reshape(-1, eeg_data.shape[-1])  # Flatten for scaling\n",
    "eeg_data = scaler.fit_transform(eeg_data)\n",
    "eeg_data = eeg_data.reshape(-1, 128, 8)  # Reshape back\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(eeg_data, stimulus_rankings, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert rankings to one-hot if classification is needed\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train - 1, num_classes=5)\n",
    "y_val_one_hot = tf.keras.utils.to_categorical(y_val - 1, num_classes=5)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test - 1, num_classes=5)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(128, 8), return_sequences=False),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(5, activation='softmax')  # Use softmax for classification, or change to a single neuron for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',  # Use 'mse' for regression\n",
    "              metrics=['accuracy'])  # Use ['mae'] for regression\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_one_hot, \n",
    "                    validation_data=(X_val, y_val_one_hot),\n",
    "                    epochs=20, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"eeg_lstm_model.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Info\n",
    "\n",
    "As other classifiers, SVC, NuSVC and LinearSVC take as input two arrays: an array X of shape (n_samples, n_features) holding the training samples, \n",
    "and an array y of class labels (strings or integers), of shape (n_samples):\n",
    "\n",
    "Support Vector Machine algorithms are not scale invariant, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0,1] or [-1,+1],\n",
    "or standardize it to have mean 0 and variance 1. Note that the same scaling must be applied to the test vector to obtain meaningful results. This can be done easily by using a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Simulate example dataset\n",
    "data = pd.DataFrame({\n",
    "    \"Epoch_Features\": [np.random.rand(32, 1280) for _ in range(24)],  # 32 channels, 1280 time points (sampling rate = 128 * 10 for 10 sec)\n",
    "    \"Size\": [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3], \n",
    "    \"Contrast\": [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],  \n",
    "    \"Comfort_Score\": [2, 3, 4, 7, 2, 4, 6, 7, 2, 4, 5, 7, 2, 3, 4, 6, 2, 4, 6, 7, 4, 4, 5, 7],  \n",
    "    \"Z_Score\": [2.1, 3, 2.2, 2.2, 2.2, 2.1, 1.5, 1, 3, 3, 4, 2.1, 2.1, 3, 2.2, 2.2, 2.2, 2.1, 1.5, 1, 3, 3, 4, 2.1]  \n",
    "})\n",
    "\n",
    "# Filter by Z-Score\n",
    "filtered_data = data[data['Z_Score'] > 2.0]\n",
    "\n",
    "# Flatten EEG features\n",
    "flattened_features = np.array([epoch.flatten() for epoch in filtered_data['Epoch_Features']])\n",
    "\n",
    "# Combine features\n",
    "X = np.hstack([\n",
    "    flattened_features,\n",
    "    filtered_data[['Size', 'Contrast']].values\n",
    "])\n",
    "y = filtered_data['Comfort_Score'].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split (to retain indices for Size/Contrast output)\n",
    "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "    X_scaled, y, range(len(y)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Get the corresponding Size and Contrast for the test set using test_indices\n",
    "test_data = filtered_data.iloc[test_indices]\n",
    "test_sizes = test_data['Size'].values\n",
    "test_contrasts = test_data['Contrast'].values\n",
    "\n",
    "# Define SVM model\n",
    "model = SVR(kernel='rbf', C=1.0, gamma='scale')\n",
    "\n",
    "# Cross-validation prediction\n",
    "y_pred_cv = cross_val_predict(model, X_scaled, y, cv=10)  # 10-fold cross-validation\n",
    "\n",
    "# Extract predictions only for the test set\n",
    "y_pred_test = y_pred_cv[test_indices]\n",
    "\n",
    "# Print out the Size, Contrast, and Prediction for each test epoch\n",
    "for i in range(len(y_pred_test)):\n",
    "    print(f\"Prediction: {y_pred_test[i]}, Size: {test_sizes[i]}, Contrast: {test_contrasts[i]}\")\n",
    "\n",
    "# Calculate RMSE for the cross-validation predictions on the test set\n",
    "rmse_cv = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "print(f\"RMSE (Cross-Validation): {rmse_cv}\")\n",
    "\n",
    "print(f\"Training epochs: {len(X_train)}\")\n",
    "print(f\"Testing epochs: {len(X_test)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
